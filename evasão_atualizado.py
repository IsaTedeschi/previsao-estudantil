# -*- coding: utf-8 -*-
"""Evasão-Atualizado.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IHwD4ZdwLsuY0srh4XuCugGVG9fWUqmU

UTILIZANDO DIFERENTES BIBLIOTECAS
"""

import pandas as pd

# Pegar os dados
url = '/content/drive/MyDrive/TCC/DadosFACOM-Original - Dados.csv'
df = pd.read_csv(url)

df.drop(1, axis=0, inplace=True)
df.head()

# Quantidade de linhas no arquivo
len(df)

# Quantidade de pessoas distintas no arquivo
lista_ids = list(df['Identificador'].unique())
len(lista_ids)

null_indices = df[df['MEDIA_FINAL'].isnull()].index
null_indices

# Lidando com médias nulas
df.drop(null_indices, axis=0, inplace=True)

# Lidando com Período Especial
df.replace('1° Per. Esp.', 1, inplace=True)
df.replace('2° Per. Esp.', 2, inplace=True)

# Lidando com Reprovado por frequência - media = 0
df.loc[df['SITUACAO'] == 'Repr.Freq.', 'MEDIA_FINAL'] = 0

# Tira as linhas que teve s/aproveitamento
sem_aprov = df.loc[df['SITUACAO'] == 'S/Aprov.'].index
df.drop(sem_aprov, axis=0, inplace=True)

# Tirar linhas que tem 'Ano' como Período
df.drop(df.loc[df['PERIODO'] == 'Ano'].index, axis=0, inplace=True)

# Tirar colunas irrelevantes
df.drop(['COD_ATIV_CURRIC', 'COD_CURSO', 'NUM_VERSAO', 'NOME_ATIV_CURRIC','CONCEITO', 'ID_NOTA',	'DESCR_ESTRUTURA', 'TOTAL_CH_DISC','NOME_CURSO_DIPLOMA'], axis=1, inplace=True)

df

# Transformar tudo diferente de Formado em Evadiu
df.loc[df['FORMA_EVASAO'] != 'Formado', 'FORMA_EVASAO'] = 'Evadiu'

# Quantidade de linhas pós pré-processamento
print(len(df))

# Quantidade de pessoas distintas no arquivo pós pré-processamento
lista_ids = list(df['Identificador'].unique())
len(lista_ids)

"""CRIANDO OUTRO DATABASE
-- criando database final que vai ser usado para colocar no classificador
"""

new_df = df.groupby('Identificador').first().reset_index()
new_df = new_df[['Identificador', 'FORMA_EVASAO']]
new_df = new_df.assign(MGA1=0.0, MGA2=0.0, MGA3=0.0)
new_df

"""Criando indice para colocar no novo dataframe"""

# criar uma lista com os indices

lista_ids = list(df['Identificador'].unique())
len(lista_ids)

"""COMEÇAR COM AS CONTAS"""

# Modificando o PERIODO para int para conseguir mexer nele depois
def modifica_tipo(data_aluno):
  data_aluno['PERIODO'] = data_aluno['PERIODO'].astype(int)

def calcula_mga(df):
  soma_carga = df['CH_TOTAL'].sum()
  soma_carga_media = df['CARGA_MEDIA'].sum()
  mga = soma_carga_media / soma_carga
  return mga


def monta_dataframe_final(lista_dataframes):
  mgas=[]
  for df in lista_dataframes:
    mga = calcula_mga(df)
    mgas.append(mga)

  # Get the identifier from the first dataframe
  identificador = lista_dataframes[0]['Identificador'].iloc[0]

  # Update new_df in a single step
  new_df.loc[new_df['Identificador'] == identificador, ['MGA1', 'MGA2', 'MGA3']] = mgas[:3]

def forma_notas(df):
  primeiro_semestre = (df['ANO_INGRESSO'] == df['ANO']) & (df['PERIODO_INGRESSO'] == df['PERIODO'])
  terceiro_semestre = (df['ANO_INGRESSO']+1 == df['ANO']) & (df['PERIODO_INGRESSO'] == df['PERIODO'])
  if (df['PERIODO_INGRESSO'] == 1).any():
    segundo_semestre = (df['ANO_INGRESSO'] == df['ANO']) & (df['PERIODO_INGRESSO']+1 == df['PERIODO'])
  else:
    segundo_semestre = (df['ANO_INGRESSO']+1 == df['ANO']) & (df['PERIODO_INGRESSO']-1 == df['PERIODO'])

  # Se houve desistencia sem finalizar os 3 primeiros períodos --> ele é desconsiderado
  if df[primeiro_semestre].empty or df[segundo_semestre].empty or df[terceiro_semestre].empty:
    index = new_df.loc[new_df['Identificador'] == df['Identificador'].iloc[0]].index
    new_df.drop(index, axis=0, inplace=True)
    return

  # Serparado os semestres
  data_aluno_por_semestre = [df[primeiro_semestre], df[segundo_semestre], df[terceiro_semestre]]

  # Agora chama a função de MGA e calcula ela
  monta_dataframe_final(data_aluno_por_semestre)

for id_aluno in lista_ids:
  data_aluno = df[df['Identificador']==id_aluno].copy()
  data_aluno['CARGA_MEDIA'] = data_aluno['MEDIA_FINAL'] * data_aluno['CH_TOTAL']
  # Chama função 1 --> modificar tipo de dado
  modifica_tipo(data_aluno)
  # CHAMA FUNÇÃO 1 --> RETIRAR OS SEMESTRES QUE NAO PRECISA
  forma_notas(data_aluno)
  # FAZER O MGA

new_df

# @title FORMA_EVASAO

from matplotlib import pyplot as plt
import seaborn as sns
new_df.groupby('FORMA_EVASAO').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

from sklearn.preprocessing import LabelEncoder

df_binary = new_df.copy()

# Criando o encoder
encoder = LabelEncoder()

y = df_binary["FORMA_EVASAO"]


df_binary["FORMA_EVASAO"] = encoder.fit_transform(y)


print(encoder.classes_)  # Para ver qual classe virou 0 e qual virou 1
print(df_binary[:10])  # Exemplo dos primeiros valores

new_df = df_binary.copy()

'''
FORMA DE DIMINUIR A DIMENSIONALIDADE

from sklearn.preprocessing import LabelEncoder
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Criando o encoder
encoder = LabelEncoder()

# Extraindo as classes e transformando em números
y = new_df["FORMA_EVASAO"]
new_df["FORMA_EVASAO"] = encoder.fit_transform(y)

print(encoder.classes_)  # Para ver qual classe virou 0 e qual virou 1
print(new_df[:10])  # Exemplo dos primeiros valores

# Suponha que X seja seu dataset de 3 atributos (remover a coluna de 'FORMA_EVASAO' do PCA)
X = new_df.drop(columns=["FORMA_EVASAO"])

# Reduzindo a dimensionalidade para 2
pca = PCA(n_components=2)
X_reduzido = pca.fit_transform(X)

# Visualizando os dados reduzidos
plt.scatter(X_reduzido[:, 0], X_reduzido[:, 1], c=new_df["FORMA_EVASAO"], cmap=plt.cm.bwr, edgecolors="k")
plt.xlabel("Componente Principal 1")
plt.ylabel("Componente Principal 2")
plt.title("Redução de Dimensionalidade com PCA")
plt.show()
'''

"""COMEÇAR COM O PROCESSAMENTO"""

# Quantos elementos estão em cada classe
  # 0 - Evadiu
  # 1 - Formou

new_df.groupby('FORMA_EVASAO').size()

new_df = new_df.drop('Identificador', axis=1)
new_df

# 1º modo - random oversamplin
new_df_oversmp = new_df.copy()
# 2º modo - synthetic minority oversamplying (SMOTE)
new_df_smote = new_df.copy()
# 3º modo - weight difference for classes - é feito quando for colocar no classificador
new_df_weight = new_df.copy()
# 4º modo - não alterar nada
new_df

# Para normalização
from sklearn.preprocessing import StandardScaler

from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# CASO 1

# Separando features e target
X_oversmp = new_df_oversmp.drop('FORMA_EVASAO', axis=1)
y_oversmp = new_df_oversmp['FORMA_EVASAO']


# Dividindo em treino e teste ANTES de aplicar oversampling
X_train_oversmp, X_test_oversmp, y_train_oversmp, y_test_oversmp = train_test_split(X_oversmp, y_oversmp, test_size=0.2, random_state=42)

# Inicializando o RandomOverSampler
ros = RandomOverSampler(random_state=42)

# Aplicando o oversampling
X_train_oversmp, y_train_oversmp = ros.fit_resample(X_train_oversmp, y_train_oversmp)


# Aplicando normalização APÓS o oversampling
scaler = StandardScaler()
X_train_oversmp = scaler.fit_transform(X_train_oversmp)  # Ajusta nos dados de treino
X_test_oversmp = scaler.transform(X_test_oversmp)  # Transforma os dados de teste

# CASO 2 - SMOTE

# Separando features e target
X_smote = new_df_smote.drop('FORMA_EVASAO', axis=1)
y_smote = new_df_smote['FORMA_EVASAO']

# Dividindo em treino e teste ANTES de aplicar oversampling
X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)

# Inicializando o smote
smote = SMOTE(random_state=42)

# Aplicando o smote
X_train_smote, y_train_smote = smote.fit_resample(X_train_smote, y_train_smote)

# Aplicando normalização APÓS o smote
scaler = StandardScaler()
X_train_smote = scaler.fit_transform(X_train_smote)  # Ajusta nos dados de treino
X_test_smote = scaler.transform(X_test_smote)  # Transforma os dados de teste

# CASO 4
# Separando features e target
X = new_df.drop('FORMA_EVASAO', axis=1)
y = new_df['FORMA_EVASAO']

# Dividindo em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Aplicando normalização
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)  # Ajusta nos dados de treino
X_test = scaler.transform(X_test)  # Transforma os dados de teste

"""FAZER A CLASSIFICAÇÃO COM CADA UM DOS MÉTODOS DE BALANCEAMENTO

Classificadores que vão ser usados: Random Forest, SVM, MLP, Naive Bayes, Árvore de Decisão, Regressão Logística e Regressão Linear
"""

# Data Processing
import pandas as pd
import numpy as np

# Modelling
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import RandomizedSearchCV, train_test_split

# Verificar qualidade do classificador
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, classification_report, f1_score, roc_auc_score
from scipy.stats import randint

# Tree Visualisation
from sklearn.tree import export_graphviz
from IPython.display import Image
import graphviz

# Randon forest com RO
    # We first create an instance of the Random forest model with the parameters
    # We then fit this to our training data.
    # We pass both the features and the target variable so the model can learn.
modelo_oversmp = RandomForestClassifier(criterion="gini", max_depth=3, random_state=42)
modelo_oversmp.fit(X_train_oversmp, y_train_oversmp) # Modelo
y_pred_oversmp_randomforest = modelo_oversmp.predict(X_test_oversmp) # Predição

# Randon forest com SMOTE
modelo_smote = RandomForestClassifier(criterion="gini", max_depth=3, random_state=42)
modelo_smote.fit(X_train_smote, y_train_smote) # Modelo
y_pred_smote_randomforest = modelo_smote.predict(X_test_smote) # Predição

# Randon forest com WC
modelo_weightclass = RandomForestClassifier(criterion="gini", max_depth=3, random_state=42, class_weight='balanced')
modelo_weightclass.fit(X_train, y_train) # Modelo
y_pred_weightclass_randomforest = modelo_weightclass.predict(X_test) # Predição

# Randon forest sem nada
modelo = RandomForestClassifier(criterion="gini", max_depth=3, random_state=42)
modelo.fit(X_train, y_train) # Modelo
y_pred_randomforest = modelo.predict(X_test) # Predição

# Decision tree with RO
modelo_oversmp = DecisionTreeClassifier(criterion="gini", max_depth=3, random_state=42)
modelo_oversmp.fit(X_train_oversmp, y_train_oversmp) # Modelo
y_pred_oversmp_decisiontree = modelo_oversmp.predict(X_test_oversmp) # Predição

# Decision tree com SMOTE
modelo_smote = DecisionTreeClassifier(criterion="gini", max_depth=3, random_state=42)
modelo_smote.fit(X_train_smote, y_train_smote) # Modelo
y_pred_smote_decisiontree = modelo_smote.predict(X_test_smote) # Predição

# Decision tree com WC
modelo_weightclass = DecisionTreeClassifier(criterion="gini", max_depth=3, random_state=42, class_weight='balanced')
modelo_weightclass.fit(X_train, y_train) # Modelo
y_pred_weightclass_decisiontree = modelo_weightclass.predict(X_test) # Predição

# Decision tree sem nada
modelo = DecisionTreeClassifier(criterion="gini", max_depth=3, random_state=42)
modelo.fit(X_train, y_train) # Modelo
y_pred_decisiontree = modelo.predict(X_test) # Predição

# SVM with RO
modelo_oversmp = svm.SVC(kernel='linear')
modelo_oversmp.fit(X_train_oversmp, y_train_oversmp) # Modelo
y_pred_oversmp_svm = modelo_oversmp.predict(X_test_oversmp) # Predição

# SVM com SMOTE
modelo_smote = svm.SVC(kernel='linear')
modelo_smote.fit(X_train_smote, y_train_smote) # Modelo
y_pred_smote_svm = modelo_smote.predict(X_test_smote) # Predição

# SVM com WC
modelo_weightclass = svm.SVC(kernel='linear', class_weight="balanced")
modelo_weightclass.fit(X_train, y_train) # Modelo
y_pred_weightclass_svm = modelo_weightclass.predict(X_test) # Predição

# SVM sem nada
modelo = svm.SVC(kernel='linear')
modelo.fit(X_train, y_train) # Modelo
y_pred_svm = modelo.predict(X_test) # Predição

# Regressão Logística with RO
modelo_oversmp = LogisticRegression(random_state=16)
modelo_oversmp.fit(X_train_oversmp, y_train_oversmp) # Modelo
y_pred_oversmp_rlogistica = modelo_oversmp.predict(X_test_oversmp) # Predição

# Regressão Logística com SMOTE
modelo_smote = LogisticRegression(random_state=16)
modelo_smote.fit(X_train_smote, y_train_smote) # Modelo
y_pred_smote_rlogistica = modelo_smote.predict(X_test_smote) # Predição

# Regressão Logística com WC
modelo_weightclass = LogisticRegression(random_state=16, class_weight="balanced")
modelo_weightclass.fit(X_train, y_train) # Modelo
y_pred_weightclass_rlogistica = modelo_weightclass.predict(X_test) # Predição

# Regressão Logística sem nada
modelo = LogisticRegression(random_state=16)
modelo.fit(X_train, y_train) # Modelo
y_pred_rlogistica = modelo.predict(X_test) # Predição

# MLP with RO
modelo_oversmp = MLPClassifier(hidden_layer_sizes=(8,), max_iter=1000, random_state=42)
modelo_oversmp.fit(X_train_oversmp, y_train_oversmp) # Modelo
y_pred_oversmp_mlp = modelo_oversmp.predict(X_test_oversmp) # Predição

# MLP com SMOTE
modelo_smote = MLPClassifier(hidden_layer_sizes=(8,), max_iter=1000, random_state=42)
modelo_smote.fit(X_train_smote, y_train_smote) # Modelo
y_pred_smote_mlp = modelo_smote.predict(X_test_smote) # Predição

# MLP com WC
 # NÃO EXISTE

# MLP sem nada
modelo = MLPClassifier(hidden_layer_sizes=(8,), max_iter=1000, random_state=42)
modelo.fit(X_train, y_train) # Modelo
y_pred_mlp = modelo.predict(X_test) # Predição

# ALUNO EXEMPLO PARA TESTAR O MODELO
  # Dado um conjunto de notas, qual é a probabilidade do aluno evadir

colunas = X_smote.columns  # usa as mesmas colunas do seu dataframe original
novo_aluno_df = pd.DataFrame([[42.444444, 60.875000, 46.000000]], columns=colunas)
novo_aluno_norm = scaler.transform(novo_aluno_df)

# Predição com o modelo já treinado
pred_smote_mlp = modelo_smote.predict(novo_aluno_norm)
print("Predição:", pred_smote_mlp[0])  # 0 = evadiu, 1 = não evadiu (por exemplo)

# Naive Bayes with RO
modelo_oversmp = GaussianNB()
modelo_oversmp.fit(X_train_oversmp, y_train_oversmp) # Modelo
y_pred_oversmp_naivebayes = modelo_oversmp.predict(X_test_oversmp) # Predição

# Naive Bayes com SMOTE
modelo_smote = GaussianNB()
modelo_smote.fit(X_train_smote, y_train_smote) # Modelo
y_pred_smote_naivebayes = modelo_smote.predict(X_test_smote) # Predição

# Naive Bayes com WC
   # NÃO EXISTE

# Naive Bayes sem nada
modelo = GaussianNB()
modelo.fit(X_train, y_train) # Modelo
y_pred_naivebayes = modelo.predict(X_test) # Predição

# Regressão Linear with RO
modelo_oversmp = LogisticRegression(random_state=42)
modelo_oversmp.fit(X_train_oversmp, y_train_oversmp) # Modelo
y_pred_oversmp_rlinear = modelo_oversmp.predict(X_test_oversmp) # Predição

# Regressão Linear com SMOTE
modelo_smote = LogisticRegression(random_state=42)
modelo_smote.fit(X_train_smote, y_train_smote) # Modelo
y_pred_smote_rlinear = modelo_smote.predict(X_test_smote) # Predição

# Regressão Linear com WC
modelo_weightclass = LogisticRegression(random_state=42, class_weight="balanced")
modelo_weightclass.fit(X_train, y_train) # Modelo
y_pred_weightclass_rlinear = modelo_weightclass.predict(X_test) # Predição

# Regressão Linear sem nada
modelo = LogisticRegression(random_state=42)
modelo.fit(X_train, y_train) # Modelo
y_pred_rlinear = modelo.predict(X_test) # Predição

"""AVALIAÇÃO DOS MODELOS"""

# AVALIAÇÃO MODELO - RANDOM FOREST

    # caso 1 - oversampler
# Matriz de confusão
print('OVERSAMPLER')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_oversmp, y_pred_oversmp_randomforest)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="summer");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")


# Avaliando no conjunto de teste
accuracy_oversmp_randomforest = accuracy_score(y_test_oversmp, y_pred_oversmp_randomforest)
roc_auc_oversmp_randomforest = roc_auc_score(y_test_oversmp, modelo_oversmp.predict_proba(X_test_oversmp)[:, 1])
report = classification_report(y_test_oversmp, y_pred_oversmp_randomforest, output_dict=True)
precision_oversmp_randomforest =  report['macro avg']['precision']
recall_oversmp_randomforest = report['macro avg']['recall']
f1_oversmp_randomforest = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_oversmp_randomforest:.4f}")
print(classification_report(y_test_oversmp, y_pred_oversmp_randomforest, digits=4))
print(f"ROC AUC: {roc_auc_oversmp_randomforest:.4f}\n")




    # caso 2 - smote
# Matriz de confusão
print('SMOTE')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_smote, y_pred_smote_randomforest)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_smote_randomforest = accuracy_score(y_test_smote, y_pred_smote_randomforest)
roc_auc_smote_randomforest = roc_auc_score(y_test_smote, modelo_smote.predict_proba(X_test_smote)[:, 1])
report = classification_report(y_test_smote, y_pred_smote_randomforest, output_dict=True)
precision_smote_randomforest =  report['macro avg']['precision']
recall_smote_randomforest = report['macro avg']['recall']
f1_smote_randomforest = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_smote_randomforest:.4f}")
print(classification_report(y_test_smote, y_pred_smote_randomforest, digits=4))
print(f"ROC AUC: {roc_auc_smote_randomforest:.4f}\n")




    # caso 3 - classificador (com teste sem nada)
# Matriz de confusão
print('WEIGHT CLASS')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_weightclass_randomforest)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="viridis");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_weightclass_randomforest = accuracy_score(y_test, y_pred_weightclass_randomforest)
roc_auc_weightclass_randomforest = roc_auc_score(y_test, modelo_weightclass.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_weightclass_randomforest, output_dict=True)
precision_weightclass_randomforest =  report['macro avg']['precision']
recall_weightclass_randomforest = report['macro avg']['recall']
f1_weightclass_randomforest = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_weightclass_randomforest:.4f}")
print(classification_report(y_test, y_pred_weightclass_randomforest, digits=4))
print(f"ROC AUC: {roc_auc_weightclass_randomforest:.4f}\n")




    # caso 4 - sem nada
# Matriz de confusão
print('SEM BALANCEAMENTO')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_randomforest)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="tab20b");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_randomforest = accuracy_score(y_test, y_pred_randomforest)
roc_auc_randomforest = roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_randomforest, output_dict=True)
precision_randomforest =  report['macro avg']['precision']
recall_randomforest = report['macro avg']['recall']
f1_randomforest = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_randomforest:.4f}")
print(classification_report(y_test, y_pred_randomforest, digits=4))
print(f"ROC AUC: {roc_auc_randomforest:.4f}\n")

# AVALIAÇÃO MODELO - SVM

    # caso 1 - oversampler
# Matriz de confusão
print('OVERSAMPLER')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_oversmp, y_pred_oversmp_svm)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="summer");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_oversmp_svm = accuracy_score(y_test_oversmp, y_pred_oversmp_svm)
roc_auc_oversmp_svm = roc_auc_score(y_test_oversmp, modelo_oversmp.predict_proba(X_test_oversmp)[:, 1])
report = classification_report(y_test_oversmp, y_pred_oversmp_svm, output_dict=True)
precision_oversmp_svm =  report['macro avg']['precision']
recall_oversmp_svm = report['macro avg']['recall']
f1_oversmp_svm = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_oversmp_svm:.4f}")
print(classification_report(y_test_oversmp, y_pred_oversmp_svm, digits=4))
print(f"ROC AUC: {roc_auc_oversmp_svm:.4f}\n")




    # caso 2 - smote
# Matriz de confusão
print('SMOTE')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_smote, y_pred_smote_svm)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_smote_svm = accuracy_score(y_test_smote, y_pred_smote_svm)
roc_auc_smote_svm = roc_auc_score(y_test_smote, modelo_smote.predict_proba(X_test_smote)[:, 1])
report = classification_report(y_test_smote, y_pred_smote_svm, output_dict=True)
precision_smote_svm =  report['macro avg']['precision']
recall_smote_svm = report['macro avg']['recall']
f1_smote_svm = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_smote_svm:.4f}")
print(classification_report(y_test_smote, y_pred_smote_svm, digits=4))
print(f"ROC AUC: {roc_auc_smote_svm:.4f}\n")




    # caso 3 - classificador (com teste sem nada)
# Matriz de confusão
print('WEIGHT CLASS')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_weightclass_svm)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="viridis");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_weightclass_svm = accuracy_score(y_test, y_pred_weightclass_svm)
roc_auc_weightclass_svm = roc_auc_score(y_test, modelo_weightclass.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_weightclass_svm, output_dict=True)
precision_weightclass_svm =  report['macro avg']['precision']
recall_weightclass_svm = report['macro avg']['recall']
f1_weightclass_svm = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_weightclass_svm:.4f}")
print(classification_report(y_test, y_pred_weightclass_svm, digits=4))
print(f"ROC AUC: {roc_auc_weightclass_svm:.4f}\n")




    # caso 4 - sem nada
# Matriz de confusão
print('SEM BALANCEAMENTO')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_svm)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_svm = accuracy_score(y_test, y_pred_svm)
roc_auc_svm = roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_svm, output_dict=True)
precision_svm =  report['macro avg']['precision']
recall_svm = report['macro avg']['recall']
f1_svm = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_svm:.4f}")
print(classification_report(y_test, y_pred_svm, digits=4))
print(f"ROC AUC: {roc_auc_svm:.4f}\n")

# AVALIAÇÃO MODELO - DECISION TREE

    # caso 1 - oversampler
# Matriz de confusão
print('OVERSAMPLER')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_oversmp, y_pred_oversmp_decisiontree)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="summer");

# Avaliando no conjunto de teste
accuracy_oversmp_decisiontree = accuracy_score(y_test_oversmp, y_pred_oversmp_decisiontree)
roc_auc_oversmp_decisiontree = roc_auc_score(y_test_oversmp, modelo_oversmp.predict_proba(X_test_oversmp)[:, 1])
report = classification_report(y_test_oversmp, y_pred_oversmp_decisiontree, output_dict=True)
precision_oversmp_decisiontree =  report['macro avg']['precision']
recall_oversmp_decisiontree = report['macro avg']['recall']
f1_oversmp_decisiontree = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_oversmp_decisiontree:.4f}")
print(classification_report(y_test_oversmp, y_pred_oversmp_decisiontree, digits=4))
print(f"ROC AUC: {roc_auc_oversmp_decisiontree:.4f}\n")




    # caso 2 - smote
# Matriz de confusão
print('SMOTE')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_smote, y_pred_smote_decisiontree)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");

# Avaliando no conjunto de teste
accuracy_smote_decisiontree = accuracy_score(y_test_smote, y_pred_smote_decisiontree)
roc_auc_smote_decisiontree = roc_auc_score(y_test_smote, modelo_smote.predict_proba(X_test_smote)[:, 1])
report = classification_report(y_test_smote, y_pred_smote_decisiontree, output_dict=True)
precision_smote_decisiontree =  report['macro avg']['precision']
recall_smote_decisiontree = report['macro avg']['recall']
f1_smote_decisiontree = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_smote_decisiontree:.4f}")
print(classification_report(y_test_smote, y_pred_smote_decisiontree, digits=4))
print(f"ROC AUC: {roc_auc_smote_decisiontree:.4f}\n")




    # caso 3 - classificador (com teste sem nada)
# Matriz de confusão
print('WEIGHT CLASS')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_weightclass_decisiontree)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="viridis");

# Avaliando no conjunto de teste
accuracy_weightclass_decisiontree = accuracy_score(y_test, y_pred_weightclass_decisiontree)
roc_auc_weightclass_decisiontree = roc_auc_score(y_test, modelo_weightclass.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_weightclass_decisiontree, output_dict=True)
precision_weightclass_decisiontree =  report['macro avg']['precision']
recall_weightclass_decisiontree = report['macro avg']['recall']
f1_weightclass_decisiontree = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_weightclass_decisiontree:.4f}")
print(classification_report(y_test, y_pred_weightclass_decisiontree, digits=4))
print(f"ROC AUC: {roc_auc_weightclass_decisiontree:.4f}\n")




    # caso 4 - sem nada
# Matriz de confusão
print('SEM BALANCEAMENTO')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_decisiontree)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");

# Avaliando no conjunto de teste
accuracy_decisiontree = accuracy_score(y_test, y_pred_decisiontree)
roc_auc_decisiontree = roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_decisiontree, output_dict=True)
precision_decisiontree =  report['macro avg']['precision']
recall_decisiontree = report['macro avg']['recall']
f1_decisiontree = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_decisiontree:.4f}")
print(classification_report(y_test, y_pred_decisiontree, digits=4))
print(f"ROC AUC: {roc_auc_decisiontree:.4f}\n")

# AVALIAÇÃO MODELO - REGRESSAO LOGISTICA

    # caso 1 - oversampler
# Matriz de confusão
print('OVERSAMPLER')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_oversmp, y_pred_oversmp_rlogistica)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="summer");

# Avaliando no conjunto de teste
accuracy_oversmp_rlogistica = accuracy_score(y_test_oversmp, y_pred_oversmp_rlogistica)
roc_auc_oversmp_rlogistica = roc_auc_score(y_test_oversmp, modelo_oversmp.predict_proba(X_test_oversmp)[:, 1])
report = classification_report(y_test_oversmp, y_pred_oversmp_rlogistica, output_dict=True)
precision_oversmp_rlogistica =  report['macro avg']['precision']
recall_oversmp_rlogistica = report['macro avg']['recall']
f1_oversmp_rlogistica = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_oversmp_rlogistica:.4f}")
print(classification_report(y_test_oversmp, y_pred_oversmp_rlogistica, digits=4))
print(f"ROC AUC: {roc_auc_oversmp_rlogistica:.4f}\n")




    # caso 2 - smote
# Matriz de confusão
print('SMOTE')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_smote, y_pred_smote_rlogistica)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");

# Avaliando no conjunto de teste
accuracy_smote_rlogistica = accuracy_score(y_test_smote, y_pred_smote_rlogistica)
roc_auc_smote_rlogistica = roc_auc_score(y_test_smote, modelo_smote.predict_proba(X_test_smote)[:, 1])
report = classification_report(y_test_smote, y_pred_smote_rlogistica, output_dict=True)
precision_smote_rlogistica =  report['macro avg']['precision']
recall_smote_rlogistica = report['macro avg']['recall']
f1_smote_rlogistica = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_smote_rlogistica:.4f}")
print(classification_report(y_test_smote, y_pred_smote_rlogistica, digits=4))
print(f"ROC AUC: {roc_auc_smote_rlogistica:.4f}\n")




    # caso 3 - classificador (com teste sem nada)
# Matriz de confusão
print('WEIGHT CLASS')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_weightclass_rlogistica)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="viridis");

# Avaliando no conjunto de teste
accuracy_weightclass_rlogistica = accuracy_score(y_test, y_pred_weightclass_rlogistica)
roc_auc_weightclass_rlogistica = roc_auc_score(y_test, modelo_weightclass.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_weightclass_rlogistica, output_dict=True)
precision_weightclass_rlogistica =  report['macro avg']['precision']
recall_weightclass_rlogistica = report['macro avg']['recall']
f1_weightclass_rlogistica = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_weightclass_rlogistica:.4f}")
print(classification_report(y_test, y_pred_weightclass_rlogistica, digits=4))
print(f"ROC AUC: {roc_auc_weightclass_rlogistica:.4f}\n")




    # caso 4 - sem nada
# Matriz de confusão
print('SEM BALANCEAMENTO')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_rlogistica)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");

# Avaliando no conjunto de teste
accuracy_rlogistica = accuracy_score(y_test, y_pred_rlogistica)
roc_auc_rlogistica = roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_rlogistica, output_dict=True)
precision_rlogistica =  report['macro avg']['precision']
recall_rlogistica = report['macro avg']['recall']
f1_rlogistica = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_rlogistica:.4f}")
print(classification_report(y_test, y_pred_rlogistica, digits=4))
print(f"ROC AUC: {roc_auc_rlogistica:.4f}\n")

# AVALIAÇÃO MODELO - MLP

    # caso 1 - oversampler
# Matriz de confusão
print('OVERSAMPLER')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_oversmp, y_pred_oversmp_mlp)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="summer");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_oversmp_mlp = accuracy_score(y_test_oversmp, y_pred_oversmp_mlp)
roc_auc_oversmp_mlp = roc_auc_score(y_test_oversmp, modelo_oversmp.predict_proba(X_test_oversmp)[:, 1])
report = classification_report(y_test_oversmp, y_pred_oversmp_mlp, output_dict=True)
precision_oversmp_mlp =  report['macro avg']['precision']
recall_oversmp_mlp = report['macro avg']['recall']
f1_oversmp_mlp = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_oversmp_mlp:.4f}")
print(classification_report(y_test_oversmp, y_pred_oversmp_mlp, digits=4))
print(f"ROC AUC: {roc_auc_oversmp_mlp:.4f}\n")




    # caso 2 - smote
# Matriz de confusão
print('SMOTE')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_smote, y_pred_smote_mlp)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_smote_mlp = accuracy_score(y_test_smote, y_pred_smote_mlp)
roc_auc_smote_mlp = roc_auc_score(y_test_smote, modelo_smote.predict_proba(X_test_smote)[:, 1])
report = classification_report(y_test_smote, y_pred_smote_mlp, output_dict=True)
precision_smote_mlp =  report['macro avg']['precision']
recall_smote_mlp = report['macro avg']['recall']
f1_smote_mlp = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_smote_mlp:.4f}")
print(classification_report(y_test_smote, y_pred_smote_mlp, digits=4))
print(f"ROC AUC: {roc_auc_smote_mlp:.4f}\n")



    # caso 3 - classificador (com teste sem nada)
# Matriz de confusão
print('WEIGHT CLASS - o classificador não possui a opção de class weights')



    # caso 4 - sem nada
# Matriz de confusão
print('SEM BALANCEAMENTO')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_mlp)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_mlp = accuracy_score(y_test, y_pred_mlp)
roc_auc_mlp = roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_mlp, output_dict=True)
precision_mlp =  report['macro avg']['precision']
recall_mlp = report['macro avg']['recall']
f1_mlp = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_mlp:.4f}")
print(classification_report(y_test, y_pred_mlp, digits=4))
print(f"ROC AUC: {roc_auc_mlp:.4f}\n")

# AVALIAÇÃO MODELO - Naive Bayes

    # caso 1 - oversampler
# Matriz de confusão
print('OVERSAMPLER')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_oversmp, y_pred_oversmp_naivebayes)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="summer");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_oversmp_naivebayes = accuracy_score(y_test_oversmp, y_pred_oversmp_naivebayes)
roc_auc_oversmp_naivebayes = roc_auc_score(y_test_oversmp, modelo_oversmp.predict_proba(X_test_oversmp)[:, 1])
report = classification_report(y_test_oversmp, y_pred_oversmp_naivebayes, output_dict=True)
precision_oversmp_naivebayes =  report['macro avg']['precision']
recall_oversmp_naivebayes = report['macro avg']['recall']
f1_oversmp_naivebayes = report['macro avg']['f1-score']


print(f"Acurácia: {accuracy_oversmp_naivebayes:.4f}")
print(classification_report(y_test_oversmp, y_pred_oversmp_naivebayes, digits=4))
print(f"ROC AUC: {roc_auc_oversmp_naivebayes:.4f}\n")




    # caso 2 - smote
# Matriz de confusão
print('SMOTE')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_smote, y_pred_smote_naivebayes)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")

# Avaliando no conjunto de teste
accuracy_smote_naivebayes = accuracy_score(y_test_smote, y_pred_smote_naivebayes)
roc_auc_smote_naivebayes = roc_auc_score(y_test_smote, modelo_smote.predict_proba(X_test_smote)[:, 1])
report = classification_report(y_test_smote, y_pred_smote_naivebayes, output_dict=True)
precision_smote_naivebayes =  report['macro avg']['precision']
recall_smote_naivebayes = report['macro avg']['recall']
f1_smote_naivebayes = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_smote_naivebayes:.4f}")
print(classification_report(y_test_smote, y_pred_smote_naivebayes, digits=4))
print(f"ROC AUC: {roc_auc_smote_naivebayes:.4f}\n")



    # caso 3 - classificador (com teste sem nada)
# Matriz de confusão
print('WEIGHT CLASS - o classificador não possui a opção de class weights')



    # caso 4 - sem nada
# Matriz de confusão
print('SEM BALANCEAMENTO')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_naivebayes)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="tab20b");
plt.xlabel("Rótulo previsto")
plt.ylabel("Rótulo real")


# Avaliando no conjunto de teste
accuracy_naivebayes = accuracy_score(y_test, y_pred_naivebayes)
roc_auc_naivebayes = roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_naivebayes, output_dict=True)
precision_naivebayes =  report['macro avg']['precision']
recall_naivebayes = report['macro avg']['recall']
f1_naivebayes = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_naivebayes:.4f}")
print(classification_report(y_test, y_pred_naivebayes, digits=4))
print(f"ROC AUC: {roc_auc_naivebayes:.4f}\n")

# AVALIAÇÃO MODELO - Regressão Linear

    # caso 1 - oversampler
# Matriz de confusão
print('OVERSAMPLER')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_oversmp, y_pred_oversmp_rlinear)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="summer");

# Avaliando no conjunto de teste
accuracy_oversmp_rlinear = accuracy_score(y_test_oversmp, y_pred_oversmp_rlinear)
roc_auc_oversmp_rlinear = roc_auc_score(y_test_oversmp, modelo_oversmp.predict_proba(X_test_oversmp)[:, 1])
report = classification_report(y_test_oversmp, y_pred_oversmp_rlinear, output_dict=True)
precision_oversmp_rlinear =  report['macro avg']['precision']
recall_oversmp_rlinear = report['macro avg']['recall']
f1_oversmp_rlinear = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_oversmp_rlinear:.4f}")
print(classification_report(y_test_oversmp, y_pred_oversmp_rlinear, digits=4))
print(f"ROC AUC: {roc_auc_oversmp_rlinear:.4f}\n")




    # caso 2 - smote
# Matriz de confusão
print('SMOTE')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test_smote, y_pred_smote_rlinear)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");

# Avaliando no conjunto de teste
accuracy_smote_rlinear = accuracy_score(y_test_smote, y_pred_smote_rlinear)
roc_auc_smote_rlinear = roc_auc_score(y_test_smote, modelo_smote.predict_proba(X_test_smote)[:, 1])
report = classification_report(y_test_smote, y_pred_smote_rlinear,output_dict=True)
precision_smote_rlinear =  report['macro avg']['precision']
recall_smote_rlinear = report['macro avg']['recall']
f1_smote_rlinear = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_smote_rlinear:.4f}")
print(classification_report(y_test_smote, y_pred_smote_rlinear, digits=4))
print(f"ROC AUC: {roc_auc_smote_rlinear:.4f}\n")



   # caso 3 - classificador (com teste sem nada)
# Matriz de confusão
print('WEIGHT CLASS')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_weightclass_rlinear)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="viridis");

# Avaliando no conjunto de teste
accuracy_weightclass_rlinear = accuracy_score(y_test, y_pred_weightclass_rlinear)
roc_auc_weightclass_rlinear = roc_auc_score(y_test, modelo_weightclass.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_weightclass_rlinear, output_dict=True)
precision_weightclass_rlinear =  report['macro avg']['precision']
recall_weightclass_rlinear = report['macro avg']['recall']
f1_weightclass_rlinear = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_weightclass_rlinear:.4f}")
print(classification_report(y_test, y_pred_weightclass_rlinear, digits=4))
print(f"ROC AUC: {roc_auc_weightclass_rlinear:.4f}\n")


    # caso 4 - sem nada
# Matriz de confusão
print('SEM BALANCEAMENTO')
print("Matriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_rlinear)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="plasma");

# Avaliando no conjunto de teste
accuracy_rlinear = accuracy_score(y_test, y_pred_rlinear)
roc_auc_rlinear = roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])
report = classification_report(y_test, y_pred_rlinear,output_dict=True)
precision_rlinear =  report['macro avg']['precision']
recall_rlinear = report['macro avg']['recall']
f1_rlinear = report['macro avg']['f1-score']

print(f"Acurácia: {accuracy_rlinear:.4f}")
print(classification_report(y_test, y_pred_rlinear, digits=4))
print(f"ROC AUC: {roc_auc_rlinear:.4f}\n")

"""GRÁFICOS COMPARATIVOS"""

# prompt: plot accuracy from randomtree with oversmp, smote, weightclass e normal

import matplotlib.pyplot as plt

# Dados de acurácia (substitua pelos seus valores reais)
accuracies = {
    'Oversampling': accuracy_oversmp_decisiontree,
    'SMOTE': accuracy_smote_decisiontree,
    'Weight Class': accuracy_weightclass_decisiontree,
    'Normal': accuracy_decisiontree,
}

# Criando o gráfico de barras
plt.figure(figsize=(10, 6))
plt.bar(accuracies.keys(), accuracies.values(), color=['blue', 'green', 'red', 'orange'])
plt.xlabel('Técnica de Balanceamento')
plt.ylabel('Acurácia')
plt.title('Comparação de Acurácia do Random Forest com Diferentes Técnicas de Balanceamento')
plt.ylim([0, 1])  # Define o limite do eixo y entre 0 e 1
plt.show()

# prompt: plot accuracy for all 7 classifiers using oversmp

import matplotlib.pyplot as plt
import numpy as np
# Dados de acurácia (substitua pelos seus valores reais)
accuracies = {
    'Logistic Regression': [accuracy_oversmp_rlogistica, accuracy_smote_rlogistica, accuracy_weightclass_rlogistica, accuracy_rlogistica],
    'MLP': [accuracy_oversmp_mlp, accuracy_smote_mlp, np.nan, accuracy_mlp],  # np.nan for weightclass as it's not applicable
    'Naive Bayes': [accuracy_oversmp_mlp, accuracy_smote_mlp, np.nan, accuracy_mlp],  # np.nan for weightclass as it's not applicable
    'Linear Regression': [accuracy_oversmp_rlinear, accuracy_smote_rlinear, accuracy_weightclass_rlinear, accuracy_rlinear],
    'Decision Tree': [accuracy_oversmp_decisiontree, accuracy_smote_decisiontree, accuracy_weightclass_decisiontree, accuracy_decisiontree],
    'SVM': [accuracy_oversmp_svm, accuracy_smote_svm, accuracy_weightclass_svm, accuracy_svm],
    'Random Forest': [accuracy_oversmp_randomforest, accuracy_smote_randomforest, accuracy_weightclass_randomforest, accuracy_randomforest]
}

# Nomes das técnicas de balanceamento
balance_techniques = ['Oversampling', 'SMOTE', 'Weight Class', 'NDA']

# Criando o gráfico de barras
plt.figure(figsize=(15, 8))

x = np.arange(len(balance_techniques))
width = 0.1  # Largura das barras

for i, (classifier, acc_list) in enumerate(accuracies.items()):
    plt.bar(x + (i - len(accuracies) / 2) * width, acc_list, width, label=classifier)

plt.xlabel('Técnica de Balanceamento')
plt.ylabel('Acurácia')
plt.title('Comparação de Acurácia dos Classificadores com Diferentes Técnicas de Balanceamento')
plt.xticks(x, balance_techniques)
plt.ylim([0, 1])  # Define o limite do eixo y entre 0 e 1
plt.legend()
plt.show()

new_df

# Criando um aluno hipotético para testar sua classificação, utilizando os algoritmos de maior desempenho
import numpy as np

modelo_smote = MLPClassifier(hidden_layer_sizes=(8,), max_iter=1000, random_state=42)
modelo_smote.fit(X_train_smote, y_train_smote) # Modelo
y_pred_smote_mlp = modelo_smote.predict(X_test_smote) # Predição


# Suponha que esse seja o scaler usado para normalizar os dados de treino
scaler = StandardScaler()


# Agora: transforme o novo aluno com o MESMO scaler
novo_aluno = np.array([[90.444444, 90.875000, 90.000000]])
novo_aluno_normalizado = scaler.transform(novo_aluno)

# Predição corrigida
predicao = y_pred_smote_mlp.predict(novo_aluno_normalizado)
print("Predição:", predicao[0])